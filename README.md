Neural Network training routines in Julia
Author: BP
Date: Wed Jan 14 12:13:26 SGT 2015
=========================================

These are implementations of Gradient Descent and their variants, stochastic gradient descent (mini-batch algorithm), dropout

The code is structure to enable ease of experimentation with different activation functions and optimization criteria.

To Do
=====
  - Autoencoder algorithm

References
==========
Andrew Ng, "CS294A Lecture Notes -- Sparse Autoencoder"


=---------------------------------


